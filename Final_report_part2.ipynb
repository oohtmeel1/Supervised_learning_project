{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Beginning of project:\n",
    "# This project took a data set from the Enron scandal of the 2000s and used it for sentiment analysis. \n",
    "# It was a fun learning experience. \n",
    "# I used regex to help clean the many random items from the dataset, \n",
    "# I used Vader sentiment to help me with the sentiment analysis itself, because I had to \n",
    "# Do it by hand\n",
    "# Vader uses a lexicon and rule based algorithm to perform this analysis\n",
    "# I then used Sklearn to perform SVm classification and test on my data\n",
    "# My goal was to explain what the overall sentiment of the company was. \n",
    "#https://www.cs.cmu.edu/~enron/\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, a ton of libraries\n",
    "# Pandas the usual, along with numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "pd.options.display.max_colwidth = 200\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Dataframe_toWork_with\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df[\"Message\"]\n",
    "Trying_small = sentences[0:10000]\n",
    "df['Compound']= \"\"\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicti = []\n",
    "for sentence in Trying_small:\n",
    "   score = analyzer.polarity_scores(sentence)[\"compound\"]\n",
    "   dicti.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trying_small1 = sentences[4040001:4050000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicti2 = []\n",
    "for sentence in Trying_small1:\n",
    "   score = analyzer.polarity_scores(sentence)[\"compound\"]\n",
    "   dicti2.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trying_small2 = sentences[7034892:7044891]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicti3 = []\n",
    "for sentence in Trying_small2:\n",
    "   score = analyzer.polarity_scores(sentence)[\"compound\"]\n",
    "   dicti3.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beginning = df[0:10000]\n",
    "middle=df[4040001:4050000]\n",
    "end=df[7034892:7044891]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beginning = df[0:10000]\n",
    "middle=df[4040001:4050000]\n",
    "end=df[7034892:7044891]\n",
    "beginning=beginning[[\"Date\",\"Message\"]]\n",
    "middle=middle[[\"Date\",\"Message\"]]\n",
    "end = end[[\"Date\",\"Message\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict10 = pd.DataFrame(dicti,columns=['Compound'])\n",
    "dat1 = pd.concat( [beginning,dict10],axis=1)\n",
    "dat1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict11 = pd.DataFrame(dicti2,columns=['Compound'])\n",
    "dat2 = pd.concat( [middle,dict11],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict12 = pd.DataFrame(dicti3,columns=['Compound'])\n",
    "end = end.reset_index(drop=True)\n",
    "dat3 = pd.concat( [end,dict12],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = (dat1,dat2,dat3)\n",
    "df_new = pd.concat(list1)\n",
    "df_new.head()\n",
    "len(df_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
